{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ab7257",
   "metadata": {},
   "source": [
    "## Reddit\n",
    "- Using Pushshift, via PSAW\n",
    "- Useful for retrieving large amount of static, historical reddit submissions/comments\n",
    "- Example script below runs a query across submissions, and then retrieves all comments within the submission\n",
    "- This is good, if the topicality of the submission holds, but is not good for passing references/relevant comments in non-matching submissions\n",
    "- Would rather not rake the search across both submissions and comments, so the first (probably stronger) assumption (initial submission topicality) has been implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b30d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from psaw import PushshiftAPI\n",
    "\n",
    "TOTAL_SUBMISSION_LIMIT = 1000\n",
    "DAY_DELTA = 30\n",
    "\n",
    "pushshift_client = PushshiftAPI()\n",
    "last_month_start_epoch = int((datetime.now() - timedelta(days=DAY_DELTA)).timestamp())\n",
    "reddit_query = \"\"\n",
    "\n",
    "subreddits = [\n",
    "    \"fiaustralia\",\n",
    "    \"ASX_Bets\",\n",
    "    \"ausstocks\",\n",
    "    \"AusProperty\",\n",
    "    \"AusFinance\",\n",
    "    \"ausstocks\",\n",
    "    \"AusEcon\",\n",
    "    \"AusPropertyChat\",\n",
    "    \"ASX\",\n",
    "    \"AustralianAccounting\",\n",
    "]\n",
    "per_subreddit_limit = math.ceil(TOTAL_SUBMISSION_LIMIT / len(subreddits))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd766e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subreddit_submissions = []\n",
    "\n",
    "for subreddit in tqdm(\n",
    "    subreddits,\n",
    "    desc=f\"Collecting {per_subreddit_limit} submissions for each subreddit..\",\n",
    "):\n",
    "    # apply search across each subreddit\n",
    "    submission_raw = list(\n",
    "        pushshift_client.search_submissions(\n",
    "            q=reddit_query,\n",
    "            after=last_month_start_epoch,\n",
    "            subreddit=subreddit,\n",
    "            filter=[\n",
    "                \"url\",\n",
    "                \"author\",\n",
    "                \"id\",\n",
    "                \"parent_id\",\n",
    "                \"link_id\",\n",
    "                \"title\",\n",
    "                \"subreddit\",\n",
    "            ],\n",
    "            limit=per_subreddit_limit,\n",
    "        )\n",
    "    )\n",
    "    submissions_formatted = pd.DataFrame([e.d_ for e in submission_raw])\n",
    "    all_subreddit_submissions.append(submissions_formatted)\n",
    "\n",
    "all_subreddit_submissions = pd.concat(all_subreddit_submissions)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494ac59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subreddit_submissions\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a list of submissions, retrieval all comments\n",
    "submissions_and_comments = []\n",
    "\n",
    "for idx, record in tqdm(\n",
    "    all_subreddit_submissions.iterrows(),\n",
    "    total=all_subreddit_submissions.shape[0],\n",
    "    desc=\"Collecting submission comments..\",\n",
    "):\n",
    "    comments_raw = list(\n",
    "        pushshift_client.search_comments(\n",
    "            after=last_month_start_epoch,\n",
    "            subreddit=record.subreddit,\n",
    "            link_id=record.id,\n",
    "            filter=[\"url\", \"author\", \"id\", \"parent_id\", \"title\", \"body\", \"subreddit\"],\n",
    "        )\n",
    "    )\n",
    "    comments_formatted = pd.DataFrame([e.d_ for e in comments_raw])\n",
    "\n",
    "    submissions_and_comments.append(\n",
    "        pd.concat([record.to_frame().transpose(), comments_formatted], sort=True)\n",
    "    )\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb0944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_submissions_and_comments = (\n",
    "    pd.concat(submissions_and_comments, sort=True)\n",
    "    # date formatting\n",
    "    .assign(\n",
    "        document_publish_date=lambda x: x.created.apply(\n",
    "            lambda y: datetime.fromtimestamp(y)\n",
    "        )\n",
    "    ).drop(labels=[\"created\", \"created_utc\"], axis=\"columns\", inplace=False)\n",
    ")\n",
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('p38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb0121aec9e40b71ec9730e04f00957539fc5aa06febb00ef12b9b6cf43c877e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
