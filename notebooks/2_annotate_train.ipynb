{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "935e67e3",
   "metadata": {},
   "source": [
    "## Annotation bootstrapping\n",
    "- via a cheap dictionary model; though any model can be used that implements the `predict_single` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b759167e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T04:26:32.546743Z",
     "start_time": "2021-09-09T04:26:32.543373Z"
    }
   },
   "outputs": [],
   "source": [
    "from clear_bow.classifier import DictionaryClassifier\n",
    "\n",
    "dictionaries = {\n",
    "    \"customer_service\": [\"customer service\", \"service\", \"experience\"],\n",
    "    \"pricing\": [\"expensive\", \"cheap\", \"dear\", \"dollars\", \"cents\"],\n",
    "    \"billing\": [\"quarterly\", \"online\", \"phone\"],\n",
    "    \"product\": [\n",
    "        \"quality\",\n",
    "        \"product\",\n",
    "        \"superior\",\n",
    "        \"inferior\",\n",
    "        \"fast\",\n",
    "        \"efficient\",\n",
    "        \"range\",\n",
    "        \"selection\",\n",
    "        \"replaced\",\n",
    "    ],\n",
    "    \"competitor\": [\"another provider\", \"competitor\", \"leaving\", \"will not return\"],\n",
    "}\n",
    "dc = DictionaryClassifier(classifier_type=\"multi_label\", label_dictionary=dictionaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e653984",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T04:26:58.256565Z",
     "start_time": "2021-09-09T04:26:35.763641Z"
    }
   },
   "outputs": [],
   "source": [
    "# verify model predictions for n examples, optionally tweak how candidate examples are retrieved\n",
    "text_col = \"text\"\n",
    "label_col = \"label\"\n",
    "\n",
    "stateful_annotations = annotate_n_examples_per_class(\n",
    "    dc,\n",
    "    df,\n",
    "    text_col,\n",
    "    n_examples=2,\n",
    "    prediction_thresh=0.7,\n",
    "    rank_candidates=True,\n",
    "    max_candidates=2,\n",
    "    label_col=label_col,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e833369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # re-iterate annotations on the same dataset (pre-existing experiment?), updating as needed\n",
    "# concat = pd.concat([(df\n",
    "#                     .query('new_text not in @stateful_annotations.new_text')\n",
    "#                     ),\n",
    "#                    stateful_annotations])\n",
    "# stateful_annotations = annotate_n_examples_per_class(dc, concat, text_col, n_examples=10, prediction_thresh=0.75, rank_candidates=True, max_candidates=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if multi-label, backfill across the label space\n",
    "stateful_annotations = backfill_multi_label_objects(\n",
    "    dc, stateful_annotations, text_col, label_col, prediction_thresh=0.7\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7aa346",
   "metadata": {},
   "source": [
    "## Flair zero/few-shot learning\n",
    "- Format tiny datset as an experimernt, train, eval etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cff7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantize annotations into usual format; some data loss here (explicit rejections => \"-1\" values)\n",
    "quantized_annotations = stateful_annotations.copy(deep=True)\n",
    "quantized_annotations[label_col] = quantized_annotations[label_col].apply(\n",
    "    threshold_one_hot_dictionary\n",
    ")\n",
    "quantized_annotations[label_col] = normalize_label_space(\n",
    "    quantized_annotations[label_col].tolist()\n",
    ")\n",
    "\n",
    "quantized_annotations = (\n",
    "    quantized_annotations\n",
    "    # ensure each record has at least one record\n",
    "    .reset_index(drop=True).pipe(lambda x: x[contains_one_label(x, label_col)])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf2e56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T04:33:20.487638Z",
     "start_time": "2021-09-09T04:33:20.460874Z"
    }
   },
   "outputs": [],
   "source": [
    "# format annotations, create experiment with usual structure\n",
    "df, label_cols = one_hot_encode_multi_label_df(quantized_annotations, label_col)\n",
    "train_dev_test_splits = create_multi_label_train_dev_test_splits(\n",
    "    df, text_col=text_col, label_cols=label_cols, split_size=0.4, label_dict=True\n",
    ")  # larger test portions RE: low support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa102656",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T04:33:23.564543Z",
     "start_time": "2021-09-09T04:33:23.552769Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_output_dir = Path(\"/Users/samhardyhey/Desktop/tars_doodle\")\n",
    "create_experiment_output_dir(experiment_output_dir, train_dev_test_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95b95df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T04:34:56.523163Z",
     "start_time": "2021-09-09T04:34:56.183338Z"
    }
   },
   "outputs": [],
   "source": [
    "res = compare_experiments_barplot(\n",
    "    experiment_paths=[experiment_output_dir],\n",
    "    title=\"TARS eval.\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('p38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb0121aec9e40b71ec9730e04f00957539fc5aa06febb00ef12b9b6cf43c877e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
