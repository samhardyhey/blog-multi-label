{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = compare_experiments_barplot(\n",
    "#     experiment_paths=[experiment_output_dir],\n",
    "#     title=\"TARS eval.\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WANDB dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from data_util import create_multi_label_train_test_splits\n",
    "\n",
    "CONFIG = yaml.safe_load(\n",
    "    Path(\n",
    "        \"/Users/samhardyhey/Desktop/blog/blog-multi-label/train/train_config.yaml\"\n",
    "    ).read_bytes()\n",
    ")\n",
    "\n",
    "# 1.1 create splits\n",
    "df = pd.read_csv(CONFIG[\"dataset\"])\n",
    "train_split, test_split = create_multi_label_train_test_splits(\n",
    "    df, label_col=CONFIG[\"label_col\"], test_size=CONFIG[\"test_size\"]\n",
    ")\n",
    "test_split, dev_split = create_multi_label_train_test_splits(\n",
    "    test_split, label_col=CONFIG[\"label_col\"], test_size=CONFIG[\"test_size\"]\n",
    ")\n",
    "\n",
    "# # 1.2 log splits\n",
    "# with wandb.init(\n",
    "#     project=CONFIG[\"wandb_project\"],\n",
    "#     name=\"reddit_aus_finance\",\n",
    "#     group=CONFIG[\"wandb_group\"],\n",
    "#     entity=\"cool_stonebreaker\",\n",
    "# ) as run:\n",
    "#     log_dataframe(run, train, \"train_split\", \"Train split\")\n",
    "#     log_dataframe(run, dev, \"dev_split\", \"Dev split\")\n",
    "#     log_dataframe(run, test, \"test_split\", \"Test split\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_util import fit_and_log_dictionary_classifier, fit_and_log_linear_svc\n",
    "\n",
    "for model in CONFIG[\"models\"]:\n",
    "    model[\"model\"]\n",
    "    # if model['name'] == 'dictionary_classifier':\n",
    "    #     fit_and_log_dictionary_classifier(train, dev, test, model)\n",
    "\n",
    "    # elif model['name'] == 'sklearn_linear_svc':\n",
    "    #     fit_and_log_linear_svc(train, dev, test, model)\n",
    "\n",
    "    # else:\n",
    "    #     print(f\"Unsupported model: {model['name']} found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus, Sentence, Token\n",
    "from flair.models import SequenceTagger, TARSClassifier, TARSTagger, TextClassifier\n",
    "from flair.tokenization import SegtokTokenizer\n",
    "\n",
    "sent = Sentence(\"hello world\", use_tokenizer=SegtokTokenizer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_util import create_classification_report\n",
    "from model.flair_tars import predict_flair_tars\n",
    "\n",
    "test_preds = test_split.assign(\n",
    "    pred=test_split[CONFIG[\"text_col\"]].apply(lambda y: predict_flair_tars(y, tars))\n",
    ")\n",
    "\n",
    "classification_report = create_classification_report(test_split, test_preds, CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_util import label_dictionary_to_label_mat\n",
    "\n",
    "label_dictionary_to_label_mat(test_preds.label)\n",
    "\n",
    "label_dictionary_to_label_mat(test_preds.pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with wandb.init(\n",
    "#         project=CONFIG[\"wandb_project\"],\n",
    "#         name=model_config[\"type\"],\n",
    "#         group=CONFIG[\"wandb_group\"],\n",
    "#         entity=CONFIG[\"wandb_entity\"],\n",
    "#     ) as run:\n",
    "#     run.dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tempfile\n",
    "\n",
    "with tempfile.TemporaryDirectory() as artefact_dir:\n",
    "    (Path(artefact_dir) / \"label_dictionary.json\").write_text(json.dumps({\"a\": 10}))\n",
    "    (Path(artefact_dir) / \"label_dictionary.json\").read_text()\n",
    "    # run.save(str(Path(artefact_dir) / 'label_dictionary.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.flair_tars import fit_and_log_flair_tars_classifier\n",
    "\n",
    "tars = fit_and_log_flair_tars_classifier(\n",
    "    train_split, dev_split, test_split, CONFIG, CONFIG[\"models\"][-1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WANDB misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "api = wandb.Api()  # refresh state of project?\n",
    "_ = [\n",
    "    run.delete()\n",
    "    for run in api.runs(path=\"cool_stonebreaker/tyre_kick\")\n",
    "    if run.name == \"inter_group_model_comparison\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear out for dev purposes\n",
    "import wandb\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "# _ = [run.delete() for run in api.runs(path=\"cool_stonebreaker/tyre_kick\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[run.name for run in api.runs(path=\"cool_stonebreaker/tyre_kick\")]\n",
    "# log_inter_group_model_comparisons(project_artifacts, CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = api.project(\"blog-multi-label-train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette(\"pastel\", 12)\n",
    "\n",
    "# plot results\n",
    "g = sns.catplot(\n",
    "    x=\"label\",\n",
    "    y=\"f1-score\",\n",
    "    hue=\"type\",\n",
    "    data=(\n",
    "        group_model_classification_reports.pipe(\n",
    "            lambda x: x[~x[\"label\"].str.contains(\"accuracy|samples|macro|micro\")]\n",
    "        )\n",
    "    ),\n",
    "    height=10,\n",
    "    kind=\"bar\",\n",
    "    ci=None,\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_xticklabels(rotation=45)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save novel plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('p38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb0121aec9e40b71ec9730e04f00957539fc5aa06febb00ef12b9b6cf43c877e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
