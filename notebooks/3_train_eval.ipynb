{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = compare_experiments_barplot(\n",
    "#     experiment_paths=[experiment_output_dir],\n",
    "#     title=\"TARS eval.\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WANDB dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../train/')\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from data_util import create_multi_label_train_test_splits\n",
    "\n",
    "CONFIG = yaml.safe_load(\n",
    "    Path(\n",
    "        \"../train/train_config.yaml\"\n",
    "    ).read_bytes()\n",
    ")\n",
    "\n",
    "# 1.1 create splits\n",
    "df = pd.read_csv(CONFIG[\"dataset\"])\n",
    "train_split, test_split = create_multi_label_train_test_splits(\n",
    "    df, label_col=CONFIG[\"label_col\"], test_size=CONFIG[\"test_size\"]\n",
    ")\n",
    "test_split, dev_split = create_multi_label_train_test_splits(\n",
    "    test_split, label_col=CONFIG[\"label_col\"], test_size=CONFIG[\"test_size\"]\n",
    ")\n",
    "\n",
    "# # 1.2 log splits\n",
    "# with wandb.init(\n",
    "#     project=CONFIG[\"wandb_project\"],\n",
    "#     name=\"reddit_aus_finance\",\n",
    "#     group=CONFIG[\"wandb_group\"],\n",
    "#     entity=\"cool_stonebreaker\",\n",
    "# ) as run:\n",
    "#     log_dataframe(run, train, \"train_split\", \"Train split\")\n",
    "#     log_dataframe(run, dev, \"dev_split\", \"Dev split\")\n",
    "#     log_dataframe(run, test, \"test_split\", \"Test split\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_util import fit_and_log_dictionary_classifier, fit_and_log_linear_svc\n",
    "\n",
    "for model in CONFIG[\"models\"]:\n",
    "    model[\"model\"]\n",
    "    # if model['name'] == 'dictionary_classifier':\n",
    "    #     fit_and_log_dictionary_classifier(train, dev, test, model)\n",
    "\n",
    "    # elif model['name'] == 'sklearn_linear_svc':\n",
    "    #     fit_and_log_linear_svc(train, dev, test, model)\n",
    "\n",
    "    # else:\n",
    "    #     print(f\"Unsupported model: {model['name']} found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus, Sentence, Token\n",
    "from flair.models import SequenceTagger, TARSClassifier, TARSTagger, TextClassifier\n",
    "from flair.tokenization import SegtokTokenizer\n",
    "\n",
    "sent = Sentence(\"hello world\", use_tokenizer=SegtokTokenizer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_util import create_classification_report\n",
    "from model.flair_tars import predict_flair_tars\n",
    "\n",
    "test_preds = test_split.assign(\n",
    "    pred=test_split[CONFIG[\"text_col\"]].apply(lambda y: predict_flair_tars(y, tars))\n",
    ")\n",
    "\n",
    "classification_report = create_classification_report(test_split, test_preds, CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_util import label_dictionary_to_label_mat\n",
    "\n",
    "label_dictionary_to_label_mat(test_preds.label)\n",
    "\n",
    "label_dictionary_to_label_mat(test_preds.pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with wandb.init(\n",
    "#         project=CONFIG[\"wandb_project\"],\n",
    "#         name=model_config[\"type\"],\n",
    "#         group=CONFIG[\"wandb_group\"],\n",
    "#         entity=CONFIG[\"wandb_entity\"],\n",
    "#     ) as run:\n",
    "#     run.dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tempfile\n",
    "\n",
    "with tempfile.TemporaryDirectory() as artefact_dir:\n",
    "    (Path(artefact_dir) / \"label_dictionary.json\").write_text(json.dumps({\"a\": 10}))\n",
    "    (Path(artefact_dir) / \"label_dictionary.json\").read_text()\n",
    "    # run.save(str(Path(artefact_dir) / 'label_dictionary.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.flair_tars import fit_and_log_flair_tars_classifier\n",
    "\n",
    "tars = fit_and_log_flair_tars_classifier(\n",
    "    train_split, dev_split, test_split, CONFIG, CONFIG[\"models\"][-1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WANDB misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "api = wandb.Api()  # refresh state of project?\n",
    "_ = [\n",
    "    run.delete()\n",
    "    for run in api.runs(path=\"cool_stonebreaker/tyre_kick\")\n",
    "    if run.name == \"inter_group_model_comparison\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear out for dev purposes\n",
    "import wandb\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "_ = [run.delete() for run in api.runs(path=\"cool_stonebreaker/tyre_kick\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[run.name for run in api.runs(path=\"cool_stonebreaker/tyre_kick\")]\n",
    "# log_inter_group_model_comparisons(project_artifacts, CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = api.project(\"blog-multi-label-train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette(\"pastel\", 12)\n",
    "\n",
    "# plot results\n",
    "g = sns.catplot(\n",
    "    x=\"label\",\n",
    "    y=\"f1-score\",\n",
    "    hue=\"type\",\n",
    "    data=(\n",
    "        group_model_classification_reports.pipe(\n",
    "            lambda x: x[~x[\"label\"].str.contains(\"accuracy|samples|macro|micro\")]\n",
    "        )\n",
    "    ),\n",
    "    height=10,\n",
    "    kind=\"bar\",\n",
    "    ci=None,\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_xticklabels(rotation=45)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"\"\"workplace\n",
    "boss, co-workers, WFH, life balance, office, culture, hybrid\n",
    "\n",
    "property\n",
    "refinance, real estate, property, landlord, loan, buy, house, rate, rent, resident, afford, mortgage, bedroom, townhouse, auction, agent, defect, layout, floor plan, builder, boom, salary\n",
    "\n",
    "tax\n",
    "tax, land tax, gst, salary sacrifice\n",
    "\n",
    "insurance\n",
    "insurance, indemnity, income protection\n",
    "\n",
    "super\n",
    "super, contribution, fund, balance, self-funded, retire, pension\n",
    "\n",
    "public institution\n",
    "watch dog, rba, central bank, mint, fair work, bond\n",
    "\n",
    "inflation\n",
    "inflation, interest rates, reserve bank, phillip lowe, rba, petrol\n",
    "\n",
    "exchange\n",
    "exchange, rate, dollar\n",
    "\n",
    "stocks\n",
    "stock, shares, invest, indexed, van guard, wealth, assets, asx, commsec, etf, return, vdhg, high growth, selfwealth, dividends, securities, buy, dip, 200\n",
    "\n",
    "toxic\n",
    "butt, salty, fuck, laughable, fool, tard, lol, bro, shit\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dicts = {}\n",
    "for e in x.split('\\n\\n'):\n",
    "    label_dicts[e.split('\\n')[0]] = sorted(e.split('\\n')[1].split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'workplace': ['WFH', 'boss', 'co-workers', 'culture', 'hybrid', 'life balance', 'office'],\n",
    "'property': ['afford', 'agent', 'auction', 'bedroom', 'boom', 'builder', 'buy', 'defect', 'floor plan', 'house', 'landlord', 'layout', 'loan', 'mortgage', 'property', 'rate', 'real estate', 'refinance', 'rent', 'resident', 'salary', 'townhouse'],\n",
    "'tax': ['gst', 'land tax', 'salary sacrifice', 'tax'],\n",
    "'insurance': ['income protection', 'indemnity', 'insurance'],\n",
    "'super': ['balance', 'contribution', 'fund', 'pension', 'retire', 'self-funded', 'super'],\n",
    "'public institution': ['bond', 'central bank', 'fair work', 'mint', 'rba', 'watch dog'],\n",
    "'inflation': ['inflation', 'interest rates', 'petrol', 'phillip lowe', 'rba', 'reserve bank'],\n",
    "'exchange': ['dollar', 'exchange', 'rate'],\n",
    "'stocks': ['200', 'assets', 'asx', 'buy', 'commsec', 'dip', 'dividends', 'etf', 'high growth', 'indexed', 'invest', 'return', 'securities', 'selfwealth', 'shares', 'stock', 'van guard', 'vdhg', 'wealth'],\n",
    "'toxic': ['bro', 'butt', 'fool', 'fuck', 'laughable', 'lol', 'salty', 'shit', 'tard']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save novel plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../train/\")\n",
    "from eval_util import *\n",
    "import wandb\n",
    "\n",
    "\n",
    "def log_inter_group_model_comparisons(project_artifacts, CONFIG):\n",
    "    group_model_classification_reports = []\n",
    "    # format, concat\n",
    "    for idx, record in (\n",
    "        project_artifacts.query('_sequence_name == \"test_classification_report\"')\n",
    "    ).iterrows():\n",
    "        group_model_classification_reports.append(\n",
    "            (\n",
    "                parse_wandb_table_artifact(record.artifact)\n",
    "                .assign(type=record.type)\n",
    "                .assign(group=record.group)\n",
    "            )\n",
    "        )\n",
    "    group_model_classification_reports = pd.concat(group_model_classification_reports)\n",
    "\n",
    "    # choose single most performant model from each group\n",
    "    group_model_classification_reports = (\n",
    "        group_model_classification_reports\n",
    "        .groupby(\"group\")\n",
    "        .apply(get_most_performant_classifier_per_group)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # create plot\n",
    "    fig = px.bar(\n",
    "        (\n",
    "            group_model_classification_reports.pipe(\n",
    "                lambda x: x[~x[\"label\"].str.contains(\"accuracy|samples|macro|micro\")]\n",
    "            )\n",
    "        ),\n",
    "        x=\"label\",\n",
    "        y=\"f1-score\",\n",
    "        color=\"type\",\n",
    "        barmode=\"group\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "    # # log plot\n",
    "    # with wandb.init(\n",
    "    #     project=CONFIG[\"wandb_project\"],\n",
    "    #     name=\"inter_group_model_comparison\",\n",
    "    #     group=\"inter_group_model_comparison\",\n",
    "    #     entity=CONFIG[\"wandb_entity\"],\n",
    "    #     job_type=\"aux_plot\",\n",
    "    # ) as run:\n",
    "    #     run.log({\"inter_group_model_comparison\": fig})\n",
    "\n",
    "api = wandb.Api()\n",
    "project_artifacts = list_all_project_artifacts(api, CONFIG)\n",
    "\n",
    "# log_inter_group_model_comparisons(project_artifacts, CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function wandb.sdk.wandb_run.restore(name: str, run_path: Union[str, NoneType] = None, replace: bool = False, root: Union[str, NoneType] = None) -> Union[NoneType, TextIO]>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>type</th>\n",
       "      <th>group</th>\n",
       "      <th>_sequence_name</th>\n",
       "      <th>artifact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;Run cool_stonebreaker/tyre_kick/axlfxb47 (fin...</td>\n",
       "      <td>flair_tars</td>\n",
       "      <td>annotation_1</td>\n",
       "      <td>test_preds</td>\n",
       "      <td>&lt;Artifact QXJ0aWZhY3Q6MjAyNzY3ODAw&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;Run cool_stonebreaker/tyre_kick/3n7um7a3 (fin...</td>\n",
       "      <td>sklearn_linear_svc</td>\n",
       "      <td>annotation_1</td>\n",
       "      <td>test_preds</td>\n",
       "      <td>&lt;Artifact QXJ0aWZhY3Q6MjAyNzY3NTk3&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;Run cool_stonebreaker/tyre_kick/tg2ec19u (fin...</td>\n",
       "      <td>dictionary_classifier</td>\n",
       "      <td>annotation_1</td>\n",
       "      <td>test_preds</td>\n",
       "      <td>&lt;Artifact QXJ0aWZhY3Q6MjAyNzY3NDQy&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 run                   type  \\\n",
       "2  <Run cool_stonebreaker/tyre_kick/axlfxb47 (fin...             flair_tars   \n",
       "4  <Run cool_stonebreaker/tyre_kick/3n7um7a3 (fin...     sklearn_linear_svc   \n",
       "6  <Run cool_stonebreaker/tyre_kick/tg2ec19u (fin...  dictionary_classifier   \n",
       "\n",
       "          group _sequence_name                             artifact  \n",
       "2  annotation_1     test_preds  <Artifact QXJ0aWZhY3Q6MjAyNzY3ODAw>  \n",
       "4  annotation_1     test_preds  <Artifact QXJ0aWZhY3Q6MjAyNzY3NTk3>  \n",
       "6  annotation_1     test_preds  <Artifact QXJ0aWZhY3Q6MjAyNzY3NDQy>  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>type</th>\n",
       "      <th>group</th>\n",
       "      <th>_sequence_name</th>\n",
       "      <th>artifact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;Run cool_stonebreaker/tyre_kick/axlfxb47 (fin...</td>\n",
       "      <td>flair_tars</td>\n",
       "      <td>annotation_1</td>\n",
       "      <td>test_preds</td>\n",
       "      <td>&lt;Artifact QXJ0aWZhY3Q6MjAyNzY3ODAw&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;Run cool_stonebreaker/tyre_kick/3n7um7a3 (fin...</td>\n",
       "      <td>sklearn_linear_svc</td>\n",
       "      <td>annotation_1</td>\n",
       "      <td>test_preds</td>\n",
       "      <td>&lt;Artifact QXJ0aWZhY3Q6MjAyNzY3NTk3&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;Run cool_stonebreaker/tyre_kick/tg2ec19u (fin...</td>\n",
       "      <td>dictionary_classifier</td>\n",
       "      <td>annotation_1</td>\n",
       "      <td>test_preds</td>\n",
       "      <td>&lt;Artifact QXJ0aWZhY3Q6MjAyNzY3NDQy&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 run                   type  \\\n",
       "2  <Run cool_stonebreaker/tyre_kick/axlfxb47 (fin...             flair_tars   \n",
       "4  <Run cool_stonebreaker/tyre_kick/3n7um7a3 (fin...     sklearn_linear_svc   \n",
       "6  <Run cool_stonebreaker/tyre_kick/tg2ec19u (fin...  dictionary_classifier   \n",
       "\n",
       "          group _sequence_name                             artifact  \n",
       "2  annotation_1     test_preds  <Artifact QXJ0aWZhY3Q6MjAyNzY3ODAw>  \n",
       "4  annotation_1     test_preds  <Artifact QXJ0aWZhY3Q6MjAyNzY3NTk3>  \n",
       "6  annotation_1     test_preds  <Artifact QXJ0aWZhY3Q6MjAyNzY3NDQy>  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model restoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run               <Run cool_stonebreaker/tyre_kick/axlfxb47 (fin...\n",
       "type                                                     flair_tars\n",
       "group                                                  annotation_1\n",
       "_sequence_name                                           test_preds\n",
       "artifact                        <Artifact QXJ0aWZhY3Q6MjAyNzY3ODAw>\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='/root/blog-multi-label/notebooks/best-model.pt' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-26 00:07:10,087 loading file ./best-model.pt\n"
     ]
    }
   ],
   "source": [
    "# flair\n",
    "from flair.models import TARSClassifier\n",
    "\n",
    "project_artifacts.iloc[0]\n",
    "wandb.restore('best-model.pt', '/'.join(project_artifacts.iloc[0].run.path))\n",
    "\n",
    "tars = TARSClassifier.load('./best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'public_institution': 0.0,\n",
       " 'property': 0.0,\n",
       " 'stocks': 0.0,\n",
       " 'tax': 0.0,\n",
       " 'exchange': 0.0,\n",
       " 'inflation': 0.0,\n",
       " 'toxic': 0.0,\n",
       " 'super': 0.0,\n",
       " 'insurance': 0.0,\n",
       " 'workplace': 0.0}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data import Corpus, Sentence\n",
    "from flair.tokenization import SegtokTokenizer\n",
    "\n",
    "def create_flair_classification_sentence(text, label_object, label_type=\"class\"):\n",
    "    sentence = Sentence(text, use_tokenizer=SegtokTokenizer())\n",
    "    for label in [k for k, v in label_object.items() if v > 0]:\n",
    "        sentence.add_label(label_type, label, 1.0)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def predict_flair_tars(text, flair_tars_model):\n",
    "    sentence = Sentence(text)\n",
    "    labels = flair_tars_model.get_current_label_dictionary().get_items()\n",
    "    flair_tars_model.predict(sentence)\n",
    "    pred_dict = {label: 0.0 for label in labels}\n",
    "    for e in sentence.labels:\n",
    "        label = e.to_dict()[\"value\"]\n",
    "        confidence = round(float(e.to_dict()[\"confidence\"]), 2)\n",
    "        pred_dict[label] = confidence\n",
    "    return pred_dict\n",
    "\n",
    "predict_flair_tars('hello world', tars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn\n",
    "from joblib import load\n",
    "\n",
    "wandb.restore('model.joblib', '/'.join(project_artifacts.query('type == \"sklearn_linear_svc\"').iloc[0].run.path))\n",
    "sklearn_linear_svc = load('./model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sklearn_linear_svc(text, sklearn_linear_svc_model):\n",
    "    return dict(\n",
    "        zip(\n",
    "            label_dictionary_to_label_mat(\n",
    "                test_split[CONFIG[\"label_col\"]]\n",
    "            ).columns.values,\n",
    "            sklearn_linear_svc_model.predict([text])[0].toarray()[0],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary classifier\n",
    "wandb.restore('label_dictionary.json', '/'.join(project_artifacts.query('type == \"dictionary_classifier\"').iloc[0].run.path))\n",
    "\n",
    "from clear_bow.classifier import DictionaryClassifier\n",
    "import srsly\n",
    "\n",
    "dc = DictionaryClassifier(classifier_type='multi_label', label_dictionary=srsly.read_json('./label_dictionary.json'))\n",
    "dc.predict_single('hello world')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('p38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0a3389de74b7ec3a6acaa3d6c3d81172f0da4390709f30c0434c73a0ff8c437"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
