{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = compare_experiments_barplot(\n",
    "#     experiment_paths=[experiment_output_dir],\n",
    "#     title=\"TARS eval.\",\n",
    "# )\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WANDB dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../train/\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from data_util import create_multi_label_train_test_splits\n",
    "\n",
    "CONFIG = yaml.safe_load(Path(\"../train/train_config.yaml\").read_bytes())\n",
    "\n",
    "# 1.1 create splits\n",
    "df = pd.read_csv(CONFIG[\"dataset\"])\n",
    "train_split, test_split = create_multi_label_train_test_splits(\n",
    "    df, label_col=CONFIG[\"label_col\"], test_size=CONFIG[\"test_size\"]\n",
    ")\n",
    "test_split, dev_split = create_multi_label_train_test_splits(\n",
    "    test_split, label_col=CONFIG[\"label_col\"], test_size=CONFIG[\"test_size\"]\n",
    ")\n",
    "\n",
    "# # 1.2 log splits\n",
    "# with wandb.init(\n",
    "#     project=CONFIG[\"wandb_project\"],\n",
    "#     name=\"reddit_aus_finance\",\n",
    "#     group=CONFIG[\"wandb_group\"],\n",
    "#     entity=\"cool_stonebreaker\",\n",
    "# ) as run:\n",
    "#     log_dataframe(run, train, \"train_split\", \"Train split\")\n",
    "#     log_dataframe(run, dev, \"dev_split\", \"Dev split\")\n",
    "#     log_dataframe(run, test, \"test_split\", \"Test split\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_util import fit_and_log_dictionary_classifier, fit_and_log_linear_svc\n",
    "\n",
    "for model in CONFIG[\"models\"]:\n",
    "    model[\"model\"]\n",
    "    # if model['name'] == 'dictionary_classifier':\n",
    "    #     fit_and_log_dictionary_classifier(train, dev, test, model)\n",
    "\n",
    "    # elif model['name'] == 'sklearn_linear_svc':\n",
    "    #     fit_and_log_linear_svc(train, dev, test, model)\n",
    "\n",
    "    # else:\n",
    "    #     print(f\"Unsupported model: {model['name']} found\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus, Sentence, Token\n",
    "from flair.models import SequenceTagger, TARSClassifier, TARSTagger, TextClassifier\n",
    "from flair.tokenization import SegtokTokenizer\n",
    "\n",
    "sent = Sentence(\"hello world\", use_tokenizer=SegtokTokenizer())\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_util import create_classification_report\n",
    "from model.flair_tars import predict_flair_tars\n",
    "\n",
    "test_preds = test_split.assign(\n",
    "    pred=test_split[CONFIG[\"text_col\"]].apply(lambda y: predict_flair_tars(y, tars))\n",
    ")\n",
    "\n",
    "classification_report = create_classification_report(test_split, test_preds, CONFIG)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_util import label_dictionary_to_label_mat\n",
    "\n",
    "label_dictionary_to_label_mat(test_preds.label)\n",
    "\n",
    "label_dictionary_to_label_mat(test_preds.pred)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with wandb.init(\n",
    "#         project=CONFIG[\"wandb_project\"],\n",
    "#         name=model_config[\"type\"],\n",
    "#         group=CONFIG[\"wandb_group\"],\n",
    "#         entity=CONFIG[\"wandb_entity\"],\n",
    "#     ) as run:\n",
    "#     run.dir\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tempfile\n",
    "\n",
    "with tempfile.TemporaryDirectory() as artefact_dir:\n",
    "    (Path(artefact_dir) / \"label_dictionary.json\").write_text(json.dumps({\"a\": 10}))\n",
    "    (Path(artefact_dir) / \"label_dictionary.json\").read_text()\n",
    "    # run.save(str(Path(artefact_dir) / 'label_dictionary.json'))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.flair_tars import fit_and_log_flair_tars_classifier\n",
    "\n",
    "tars = fit_and_log_flair_tars_classifier(\n",
    "    train_split, dev_split, test_split, CONFIG, CONFIG[\"models\"][-1]\n",
    ")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WANDB misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "api = wandb.Api()  # refresh state of project?\n",
    "_ = [\n",
    "    run.delete()\n",
    "    for run in api.runs(path=\"cool_stonebreaker/tyre_kick\")\n",
    "    if run.name == \"inter_group_model_comparison\"\n",
    "]\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear out for dev purposes\n",
    "import wandb\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "_ = [run.delete() for run in api.runs(path=\"cool_stonebreaker/tyre_kick\")]\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[run.name for run in api.runs(path=\"cool_stonebreaker/tyre_kick\")]\n",
    "# log_inter_group_model_comparisons(project_artifacts, CONFIG)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = api.project(\"blog-multi-label-train\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette(\"pastel\", 12)\n",
    "\n",
    "# plot results\n",
    "g = sns.catplot(\n",
    "    x=\"label\",\n",
    "    y=\"f1-score\",\n",
    "    hue=\"type\",\n",
    "    data=(\n",
    "        group_model_classification_reports.pipe(\n",
    "            lambda x: x[~x[\"label\"].str.contains(\"accuracy|samples|macro|micro\")]\n",
    "        )\n",
    "    ),\n",
    "    height=10,\n",
    "    kind=\"bar\",\n",
    "    ci=None,\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_xticklabels(rotation=45)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"\"\"workplace\n",
    "boss, co-workers, WFH, life balance, office, culture, hybrid\n",
    "\n",
    "property\n",
    "refinance, real estate, property, landlord, loan, buy, house, rate, rent, resident, afford, mortgage, bedroom, townhouse, auction, agent, defect, layout, floor plan, builder, boom, salary\n",
    "\n",
    "tax\n",
    "tax, land tax, gst, salary sacrifice\n",
    "\n",
    "insurance\n",
    "insurance, indemnity, income protection\n",
    "\n",
    "super\n",
    "super, contribution, fund, balance, self-funded, retire, pension\n",
    "\n",
    "public institution\n",
    "watch dog, rba, central bank, mint, fair work, bond\n",
    "\n",
    "inflation\n",
    "inflation, interest rates, reserve bank, phillip lowe, rba, petrol\n",
    "\n",
    "exchange\n",
    "exchange, rate, dollar\n",
    "\n",
    "stocks\n",
    "stock, shares, invest, indexed, van guard, wealth, assets, asx, commsec, etf, return, vdhg, high growth, selfwealth, dividends, securities, buy, dip, 200\n",
    "\n",
    "toxic\n",
    "butt, salty, fuck, laughable, fool, tard, lol, bro, shit\"\"\"\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dicts = {}\n",
    "for e in x.split(\"\\n\\n\"):\n",
    "    label_dicts[e.split(\"\\n\")[0]] = sorted(e.split(\"\\n\")[1].split(\", \"))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"workplace\": [\n",
    "        \"WFH\",\n",
    "        \"boss\",\n",
    "        \"co-workers\",\n",
    "        \"culture\",\n",
    "        \"hybrid\",\n",
    "        \"life balance\",\n",
    "        \"office\",\n",
    "    ],\n",
    "    \"property\": [\n",
    "        \"afford\",\n",
    "        \"agent\",\n",
    "        \"auction\",\n",
    "        \"bedroom\",\n",
    "        \"boom\",\n",
    "        \"builder\",\n",
    "        \"buy\",\n",
    "        \"defect\",\n",
    "        \"floor plan\",\n",
    "        \"house\",\n",
    "        \"landlord\",\n",
    "        \"layout\",\n",
    "        \"loan\",\n",
    "        \"mortgage\",\n",
    "        \"property\",\n",
    "        \"rate\",\n",
    "        \"real estate\",\n",
    "        \"refinance\",\n",
    "        \"rent\",\n",
    "        \"resident\",\n",
    "        \"salary\",\n",
    "        \"townhouse\",\n",
    "    ],\n",
    "    \"tax\": [\"gst\", \"land tax\", \"salary sacrifice\", \"tax\"],\n",
    "    \"insurance\": [\"income protection\", \"indemnity\", \"insurance\"],\n",
    "    \"super\": [\n",
    "        \"balance\",\n",
    "        \"contribution\",\n",
    "        \"fund\",\n",
    "        \"pension\",\n",
    "        \"retire\",\n",
    "        \"self-funded\",\n",
    "        \"super\",\n",
    "    ],\n",
    "    \"public institution\": [\n",
    "        \"bond\",\n",
    "        \"central bank\",\n",
    "        \"fair work\",\n",
    "        \"mint\",\n",
    "        \"rba\",\n",
    "        \"watch dog\",\n",
    "    ],\n",
    "    \"inflation\": [\n",
    "        \"inflation\",\n",
    "        \"interest rates\",\n",
    "        \"petrol\",\n",
    "        \"phillip lowe\",\n",
    "        \"rba\",\n",
    "        \"reserve bank\",\n",
    "    ],\n",
    "    \"exchange\": [\"dollar\", \"exchange\", \"rate\"],\n",
    "    \"stocks\": [\n",
    "        \"200\",\n",
    "        \"assets\",\n",
    "        \"asx\",\n",
    "        \"buy\",\n",
    "        \"commsec\",\n",
    "        \"dip\",\n",
    "        \"dividends\",\n",
    "        \"etf\",\n",
    "        \"high growth\",\n",
    "        \"indexed\",\n",
    "        \"invest\",\n",
    "        \"return\",\n",
    "        \"securities\",\n",
    "        \"selfwealth\",\n",
    "        \"shares\",\n",
    "        \"stock\",\n",
    "        \"van guard\",\n",
    "        \"vdhg\",\n",
    "        \"wealth\",\n",
    "    ],\n",
    "    \"toxic\": [\n",
    "        \"bro\",\n",
    "        \"butt\",\n",
    "        \"fool\",\n",
    "        \"fuck\",\n",
    "        \"laughable\",\n",
    "        \"lol\",\n",
    "        \"salty\",\n",
    "        \"shit\",\n",
    "        \"tard\",\n",
    "    ],\n",
    "}\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save novel plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../train/\")\n",
    "import wandb\n",
    "from eval_util import (\n",
    "    CONFIG,\n",
    "    get_most_performant_classifier_per_group,\n",
    "    list_all_project_artifacts,\n",
    "    parse_wandb_table_artifact,\n",
    "    pd,\n",
    "    px,\n",
    ")\n",
    "\n",
    "\n",
    "def log_inter_group_model_comparisons(project_artifacts, CONFIG):\n",
    "    group_model_classification_reports = []\n",
    "    # format, concat\n",
    "    for idx, record in (\n",
    "        project_artifacts.query('_sequence_name == \"test_classification_report\"')\n",
    "    ).iterrows():\n",
    "        group_model_classification_reports.append(\n",
    "            (\n",
    "                parse_wandb_table_artifact(record.artifact)\n",
    "                .assign(type=record.type)\n",
    "                .assign(group=record.group)\n",
    "            )\n",
    "        )\n",
    "    group_model_classification_reports = pd.concat(group_model_classification_reports)\n",
    "\n",
    "    # choose single most performant model from each group\n",
    "    group_model_classification_reports = (\n",
    "        group_model_classification_reports.groupby(\"group\")\n",
    "        .apply(get_most_performant_classifier_per_group)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # create plot\n",
    "    fig = px.bar(\n",
    "        (\n",
    "            group_model_classification_reports.pipe(\n",
    "                lambda x: x[~x[\"label\"].str.contains(\"accuracy|samples|macro|micro\")]\n",
    "            )\n",
    "        ),\n",
    "        x=\"label\",\n",
    "        y=\"f1-score\",\n",
    "        color=\"type\",\n",
    "        barmode=\"group\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "    # # log plot\n",
    "    # with wandb.init(\n",
    "    #     project=CONFIG[\"wandb_project\"],\n",
    "    #     name=\"inter_group_model_comparison\",\n",
    "    #     group=\"inter_group_model_comparison\",\n",
    "    #     entity=CONFIG[\"wandb_entity\"],\n",
    "    #     job_type=\"aux_plot\",\n",
    "    # ) as run:\n",
    "    #     run.log({\"inter_group_model_comparison\": fig})\n",
    "\n",
    "\n",
    "api = wandb.Api()\n",
    "project_artifacts = list_all_project_artifacts(api, CONFIG)\n",
    "\n",
    "# log_inter_group_model_comparisons(project_artifacts, CONFIG)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.restore\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_records\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_records\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model restoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flair\n",
    "from flair.models import TARSClassifier\n",
    "\n",
    "project_artifacts.iloc[0]\n",
    "wandb.restore(\"best-model.pt\", \"/\".join(project_artifacts.iloc[0].run.path))\n",
    "\n",
    "tars = TARSClassifier.load(\"./best-model.pt\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus, Sentence\n",
    "from flair.tokenization import SegtokTokenizer\n",
    "\n",
    "\n",
    "def create_flair_classification_sentence(text, label_object, label_type=\"class\"):\n",
    "    sentence = Sentence(text, use_tokenizer=SegtokTokenizer())\n",
    "    for label in [k for k, v in label_object.items() if v > 0]:\n",
    "        sentence.add_label(label_type, label, 1.0)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def predict_flair_tars(text, flair_tars_model):\n",
    "    sentence = Sentence(text)\n",
    "    labels = flair_tars_model.get_current_label_dictionary().get_items()\n",
    "    flair_tars_model.predict(sentence)\n",
    "    pred_dict = {label: 0.0 for label in labels}\n",
    "    for e in sentence.labels:\n",
    "        label = e.to_dict()[\"value\"]\n",
    "        confidence = round(float(e.to_dict()[\"confidence\"]), 2)\n",
    "        pred_dict[label] = confidence\n",
    "    return pred_dict\n",
    "\n",
    "\n",
    "predict_flair_tars(\"hello world\", tars)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn\n",
    "from joblib import load\n",
    "\n",
    "wandb.restore(\n",
    "    \"model.joblib\",\n",
    "    \"/\".join(project_artifacts.query('type == \"sklearn_linear_svc\"').iloc[0].run.path),\n",
    ")\n",
    "sklearn_linear_svc = load(\"./model.joblib\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sklearn_linear_svc(text, sklearn_linear_svc_model):\n",
    "    return dict(\n",
    "        zip(\n",
    "            label_dictionary_to_label_mat(\n",
    "                test_split[CONFIG[\"label_col\"]]\n",
    "            ).columns.values,\n",
    "            sklearn_linear_svc_model.predict([text])[0].toarray()[0],\n",
    "        )\n",
    "    )\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary classifier\n",
    "wandb.restore(\n",
    "    \"label_dictionary.json\",\n",
    "    \"/\".join(\n",
    "        project_artifacts.query('type == \"dictionary_classifier\"').iloc[0].run.path\n",
    "    ),\n",
    ")\n",
    "\n",
    "import srsly\n",
    "from clear_bow.classifier import DictionaryClassifier\n",
    "\n",
    "dc = DictionaryClassifier(\n",
    "    classifier_type=\"multi_label\",\n",
    "    label_dictionary=srsly.read_json(\"./label_dictionary.json\"),\n",
    ")\n",
    "dc.predict_single(\"hello world\")\n",
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('p38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0a3389de74b7ec3a6acaa3d6c3d81172f0da4390709f30c0434c73a0ff8c437"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
