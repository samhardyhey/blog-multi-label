{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = compare_experiments_barplot(\n",
    "#     experiment_paths=[experiment_output_dir],\n",
    "#     title=\"TARS eval.\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.width', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>document_publish_date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>wineisasalad</td>\n",
       "      <td>ioz9099</td>\n",
       "      <td>AusProperty</td>\n",
       "      <td>2022-09-18 21:02:39</td>\n",
       "      <td>Just wondering if they got the mufti or if the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>deadpanjunkie</td>\n",
       "      <td>iomaucs</td>\n",
       "      <td>AusPropertyChat</td>\n",
       "      <td>2022-09-16 03:05:36</td>\n",
       "      <td>I'm a Kiwi living in Sydney, if your deposit i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>todjo929</td>\n",
       "      <td>ion1yp0</td>\n",
       "      <td>AustralianAccounting</td>\n",
       "      <td>2022-09-16 08:12:46</td>\n",
       "      <td>Also have to point out that he can't claim if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>kekistani118</td>\n",
       "      <td>x0oeb4</td>\n",
       "      <td>ausstocks</td>\n",
       "      <td>2022-08-29 13:10:30</td>\n",
       "      <td>anson resources ltd ASN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>light-light-light</td>\n",
       "      <td>ioq3d4y</td>\n",
       "      <td>AusProperty</td>\n",
       "      <td>2022-09-16 22:20:31</td>\n",
       "      <td>The reserve bank printed a lot of money. The f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>Always_Intuitive</td>\n",
       "      <td>xdx82i</td>\n",
       "      <td>AusPropertyChat</td>\n",
       "      <td>2022-09-14 09:20:59</td>\n",
       "      <td>Strata Building Insurance &amp;amp; Excess Payment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>Plupsnup</td>\n",
       "      <td>xdnzuy</td>\n",
       "      <td>AusEcon</td>\n",
       "      <td>2022-09-14 00:57:17</td>\n",
       "      <td>‘Unprecedented’: Housing crisis gets even wors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>MZootSuit</td>\n",
       "      <td>ion3ecb</td>\n",
       "      <td>fiaustralia</td>\n",
       "      <td>2022-09-16 08:33:13</td>\n",
       "      <td>:-)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>ChZakalwe</td>\n",
       "      <td>ioxm48h</td>\n",
       "      <td>ASX_Bets</td>\n",
       "      <td>2022-09-18 14:53:31</td>\n",
       "      <td>You mean you western losers living in the past?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>deltabay17</td>\n",
       "      <td>iojzk2y</td>\n",
       "      <td>fiaustralia</td>\n",
       "      <td>2022-09-15 17:17:08</td>\n",
       "      <td>Neither. They both invest in China which is bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author       id             subreddit document_publish_date  \\\n",
       "1357       wineisasalad  ioz9099           AusProperty   2022-09-18 21:02:39   \n",
       "2367      deadpanjunkie  iomaucs       AusPropertyChat   2022-09-16 03:05:36   \n",
       "2822           todjo929  ion1yp0  AustralianAccounting   2022-09-16 08:12:46   \n",
       "2126       kekistani118   x0oeb4             ausstocks   2022-08-29 13:10:30   \n",
       "1544  light-light-light  ioq3d4y           AusProperty   2022-09-16 22:20:31   \n",
       "2415   Always_Intuitive   xdx82i       AusPropertyChat   2022-09-14 09:20:59   \n",
       "2227           Plupsnup   xdnzuy               AusEcon   2022-09-14 00:57:17   \n",
       "410           MZootSuit  ion3ecb           fiaustralia   2022-09-16 08:33:13   \n",
       "761           ChZakalwe  ioxm48h              ASX_Bets   2022-09-18 14:53:31   \n",
       "436          deltabay17  iojzk2y           fiaustralia   2022-09-15 17:17:08   \n",
       "\n",
       "                                                   text  \n",
       "1357  Just wondering if they got the mufti or if the...  \n",
       "2367  I'm a Kiwi living in Sydney, if your deposit i...  \n",
       "2822  Also have to point out that he can't claim if ...  \n",
       "2126                            anson resources ltd ASN  \n",
       "1544  The reserve bank printed a lot of money. The f...  \n",
       "2415  Strata Building Insurance &amp; Excess Payment...  \n",
       "2227  ‘Unprecedented’: Housing crisis gets even wors...  \n",
       "410                                                 :-)  \n",
       "761     You mean you western losers living in the past?  \n",
       "436   Neither. They both invest in China which is bo...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../output/reddit_aus_finance.csv').sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WANDB dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../train/\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from data_util import create_multi_label_train_test_splits\n",
    "\n",
    "CONFIG = yaml.safe_load(Path(\"../train/train_config.yaml\").read_bytes())\n",
    "\n",
    "# 1.1 create splits\n",
    "df = pd.read_csv(CONFIG[\"dataset\"])\n",
    "train_split, test_split = create_multi_label_train_test_splits(\n",
    "    df, label_col=CONFIG[\"label_col\"], test_size=CONFIG[\"test_size\"]\n",
    ")\n",
    "test_split, dev_split = create_multi_label_train_test_splits(\n",
    "    test_split, label_col=CONFIG[\"label_col\"], test_size=CONFIG[\"test_size\"]\n",
    ")\n",
    "\n",
    "# # 1.2 log splits\n",
    "# with wandb.init(\n",
    "#     project=CONFIG[\"wandb_project\"],\n",
    "#     name=\"reddit_aus_finance\",\n",
    "#     group=CONFIG[\"wandb_group\"],\n",
    "#     entity=\"cool_stonebreaker\",\n",
    "# ) as run:\n",
    "#     log_dataframe(run, train, \"train_split\", \"Train split\")\n",
    "#     log_dataframe(run, dev, \"dev_split\", \"Dev split\")\n",
    "#     log_dataframe(run, test, \"test_split\", \"Test split\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../output/reddit_aus_finance.csv').query('subreddit == \"AusPropertyChat\"').text.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_util import fit_and_log_dictionary_classifier, fit_and_log_linear_svc\n",
    "\n",
    "for model in CONFIG[\"models\"]:\n",
    "    model[\"model\"]\n",
    "    # if model['name'] == 'dictionary_classifier':\n",
    "    #     fit_and_log_dictionary_classifier(train, dev, test, model)\n",
    "\n",
    "    # elif model['name'] == 'sklearn_linear_svc':\n",
    "    #     fit_and_log_linear_svc(train, dev, test, model)\n",
    "\n",
    "    # else:\n",
    "    #     print(f\"Unsupported model: {model['name']} found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus, Sentence, Token\n",
    "from flair.models import SequenceTagger, TARSClassifier, TARSTagger, TextClassifier\n",
    "from flair.tokenization import SegtokTokenizer\n",
    "\n",
    "sent = Sentence(\"hello world\", use_tokenizer=SegtokTokenizer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_util import create_classification_report\n",
    "from model.flair_tars import predict_flair_tars\n",
    "\n",
    "test_preds = test_split.assign(\n",
    "    pred=test_split[CONFIG[\"text_col\"]].apply(lambda y: predict_flair_tars(y, tars))\n",
    ")\n",
    "\n",
    "classification_report = create_classification_report(test_split, test_preds, CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_util import label_dictionary_to_label_mat\n",
    "\n",
    "label_dictionary_to_label_mat(test_preds.label)\n",
    "\n",
    "label_dictionary_to_label_mat(test_preds.pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with wandb.init(\n",
    "#         project=CONFIG[\"wandb_project\"],\n",
    "#         name=model_config[\"type\"],\n",
    "#         group=CONFIG[\"wandb_group\"],\n",
    "#         entity=CONFIG[\"wandb_entity\"],\n",
    "#     ) as run:\n",
    "#     run.dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tempfile\n",
    "\n",
    "with tempfile.TemporaryDirectory() as artefact_dir:\n",
    "    (Path(artefact_dir) / \"label_dictionary.json\").write_text(json.dumps({\"a\": 10}))\n",
    "    (Path(artefact_dir) / \"label_dictionary.json\").read_text()\n",
    "    # run.save(str(Path(artefact_dir) / 'label_dictionary.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.flair_tars import fit_and_log_flair_tars_classifier\n",
    "\n",
    "tars = fit_and_log_flair_tars_classifier(\n",
    "    train_split, dev_split, test_split, CONFIG, CONFIG[\"models\"][-1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WANDB misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "api = wandb.Api()  # refresh state of project?\n",
    "_ = [\n",
    "    run.delete()\n",
    "    for run in api.runs(path=\"cool_stonebreaker/tyre_kick\")\n",
    "    if run.name == \"inter_group_model_comparison\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear out for dev purposes\n",
    "import wandb\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "_ = [run.delete() for run in api.runs(path=\"cool_stonebreaker/tyre_kick\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[run.name for run in api.runs(path=\"cool_stonebreaker/tyre_kick\")]\n",
    "# log_inter_group_model_comparisons(project_artifacts, CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = api.project(\"blog-multi-label-train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette(\"pastel\", 12)\n",
    "\n",
    "# plot results\n",
    "g = sns.catplot(\n",
    "    x=\"label\",\n",
    "    y=\"f1-score\",\n",
    "    hue=\"type\",\n",
    "    data=(\n",
    "        group_model_classification_reports.pipe(\n",
    "            lambda x: x[~x[\"label\"].str.contains(\"accuracy|samples|macro|micro\")]\n",
    "        )\n",
    "    ),\n",
    "    height=10,\n",
    "    kind=\"bar\",\n",
    "    ci=None,\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_xticklabels(rotation=45)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([\n",
    "        \"fiaustralia\",\n",
    "        \"ASX_Bets\",\n",
    "        \"ausstocks\",\n",
    "        \"AusProperty\",\n",
    "        \"AusFinance\",\n",
    "        \"ausstocks\",\n",
    "        \"AusEcon\",\n",
    "        \"AusPropertyChat\",\n",
    "        \"ASX\",\n",
    "        \"AustralianAccounting\",\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"\"\"workplace\n",
    "boss, co-workers, WFH, life balance, office, culture, hybrid\n",
    "\n",
    "property\n",
    "refinance, real estate, property, landlord, loan, buy, house, rate, rent, resident, afford, mortgage, bedroom, townhouse, auction, agent, defect, layout, floor plan, builder, boom, salary\n",
    "\n",
    "tax\n",
    "tax, land tax, gst, salary sacrifice\n",
    "\n",
    "insurance\n",
    "insurance, indemnity, income protection\n",
    "\n",
    "super\n",
    "super, contribution, fund, balance, self-funded, retire, pension\n",
    "\n",
    "public institution\n",
    "watch dog, rba, central bank, mint, fair work, bond\n",
    "\n",
    "inflation\n",
    "inflation, interest rates, reserve bank, phillip lowe, rba, petrol\n",
    "\n",
    "exchange\n",
    "exchange, rate, dollar\n",
    "\n",
    "stocks\n",
    "stock, shares, invest, indexed, van guard, wealth, assets, asx, commsec, etf, return, vdhg, high growth, selfwealth, dividends, securities, buy, dip, 200\n",
    "\n",
    "toxic\n",
    "butt, salty, fuck, laughable, fool, tard, lol, bro, shit\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dicts = {}\n",
    "for e in x.split(\"\\n\\n\"):\n",
    "    label_dicts[e.split(\"\\n\")[0]] = sorted(e.split(\"\\n\")[1].split(\", \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"workplace\": [\n",
    "        \"WFH\",\n",
    "        \"boss\",\n",
    "        \"co-workers\",\n",
    "        \"culture\",\n",
    "        \"hybrid\",\n",
    "        \"life balance\",\n",
    "        \"office\",\n",
    "    ],\n",
    "    \"property\": [\n",
    "        \"afford\",\n",
    "        \"agent\",\n",
    "        \"auction\",\n",
    "        \"bedroom\",\n",
    "        \"boom\",\n",
    "        \"builder\",\n",
    "        \"buy\",\n",
    "        \"defect\",\n",
    "        \"floor plan\",\n",
    "        \"house\",\n",
    "        \"landlord\",\n",
    "        \"layout\",\n",
    "        \"loan\",\n",
    "        \"mortgage\",\n",
    "        \"property\",\n",
    "        \"rate\",\n",
    "        \"real estate\",\n",
    "        \"refinance\",\n",
    "        \"rent\",\n",
    "        \"resident\",\n",
    "        \"salary\",\n",
    "        \"townhouse\",\n",
    "    ],\n",
    "    \"tax\": [\"gst\", \"land tax\", \"salary sacrifice\", \"tax\"],\n",
    "    \"insurance\": [\"income protection\", \"indemnity\", \"insurance\"],\n",
    "    \"super\": [\n",
    "        \"balance\",\n",
    "        \"contribution\",\n",
    "        \"fund\",\n",
    "        \"pension\",\n",
    "        \"retire\",\n",
    "        \"self-funded\",\n",
    "        \"super\",\n",
    "    ],\n",
    "    \"public institution\": [\n",
    "        \"bond\",\n",
    "        \"central bank\",\n",
    "        \"fair work\",\n",
    "        \"mint\",\n",
    "        \"rba\",\n",
    "        \"watch dog\",\n",
    "    ],\n",
    "    \"inflation\": [\n",
    "        \"inflation\",\n",
    "        \"interest rates\",\n",
    "        \"petrol\",\n",
    "        \"phillip lowe\",\n",
    "        \"rba\",\n",
    "        \"reserve bank\",\n",
    "    ],\n",
    "    \"exchange\": [\"dollar\", \"exchange\", \"rate\"],\n",
    "    \"stocks\": [\n",
    "        \"200\",\n",
    "        \"assets\",\n",
    "        \"asx\",\n",
    "        \"buy\",\n",
    "        \"commsec\",\n",
    "        \"dip\",\n",
    "        \"dividends\",\n",
    "        \"etf\",\n",
    "        \"high growth\",\n",
    "        \"indexed\",\n",
    "        \"invest\",\n",
    "        \"return\",\n",
    "        \"securities\",\n",
    "        \"selfwealth\",\n",
    "        \"shares\",\n",
    "        \"stock\",\n",
    "        \"van guard\",\n",
    "        \"vdhg\",\n",
    "        \"wealth\",\n",
    "    ],\n",
    "    \"toxic\": [\n",
    "        \"bro\",\n",
    "        \"butt\",\n",
    "        \"fool\",\n",
    "        \"fuck\",\n",
    "        \"laughable\",\n",
    "        \"lol\",\n",
    "        \"salty\",\n",
    "        \"shit\",\n",
    "        \"tard\",\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save novel plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../train/\")\n",
    "import wandb\n",
    "from eval_util import (\n",
    "    get_most_performant_classifier_per_group,\n",
    "    list_all_project_artifacts,\n",
    "    parse_wandb_table_artifact,\n",
    "    pd,\n",
    "    px,\n",
    ")\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def log_inter_group_model_comparisons(project_artifacts, CONFIG):\n",
    "    group_model_classification_reports = []\n",
    "    # format, concat\n",
    "    for idx, record in (\n",
    "        project_artifacts.query('_sequence_name == \"test_classification_report\"')\n",
    "    ).iterrows():\n",
    "        group_model_classification_reports.append(\n",
    "            (\n",
    "                parse_wandb_table_artifact(record.artifact)\n",
    "                .assign(type=record.type)\n",
    "                .assign(group=record.group)\n",
    "            )\n",
    "        )\n",
    "    group_model_classification_reports = pd.concat(group_model_classification_reports)\n",
    "\n",
    "    # choose single most performant model from each group\n",
    "    group_model_classification_reports = (\n",
    "        group_model_classification_reports.groupby(\"group\")\n",
    "        .apply(get_most_performant_classifier_per_group)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # create plot\n",
    "    fig = px.bar(\n",
    "        (\n",
    "            group_model_classification_reports.pipe(\n",
    "                lambda x: x[~x[\"label\"].str.contains(\"accuracy|samples|macro|micro\")]\n",
    "            )\n",
    "        ),\n",
    "        x=\"label\",\n",
    "        y=\"f1-score\",\n",
    "        color=\"type\",\n",
    "        barmode=\"group\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "    # # log plot\n",
    "    # with wandb.init(\n",
    "    #     project=CONFIG[\"wandb_project\"],\n",
    "    #     name=\"inter_group_model_comparison\",\n",
    "    #     group=\"inter_group_model_comparison\",\n",
    "    #     entity=CONFIG[\"wandb_entity\"],\n",
    "    #     job_type=\"aux_plot\",\n",
    "    # ) as run:\n",
    "    #     run.log({\"inter_group_model_comparison\": fig})\n",
    "\n",
    "\n",
    "import yaml\n",
    "CONFIG = yaml.safe_load(Path(\"../train/train_config.yaml\").read_bytes())\n",
    "\n",
    "api = wandb.Api()\n",
    "project_artifacts = list_all_project_artifacts(api, CONFIG)\n",
    "\n",
    "# log_inter_group_model_comparisons(project_artifacts, CONFIG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model restoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flair\n",
    "from flair.models import TARSClassifier\n",
    "\n",
    "project_artifacts.iloc[0]\n",
    "wandb.restore(\"best-model.pt\", \"/\".join(project_artifacts.iloc[0].run.path))\n",
    "\n",
    "tars = TARSClassifier.load(\"./best-model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus, Sentence\n",
    "from flair.tokenization import SegtokTokenizer\n",
    "\n",
    "\n",
    "def create_flair_classification_sentence(text, label_object, label_type=\"class\"):\n",
    "    sentence = Sentence(text, use_tokenizer=SegtokTokenizer())\n",
    "    for label in [k for k, v in label_object.items() if v > 0]:\n",
    "        sentence.add_label(label_type, label, 1.0)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def predict_flair_tars(text, flair_tars_model):\n",
    "    sentence = Sentence(text)\n",
    "    labels = flair_tars_model.get_current_label_dictionary().get_items()\n",
    "    flair_tars_model.predict(sentence)\n",
    "    pred_dict = {label: 0.0 for label in labels}\n",
    "    for e in sentence.labels:\n",
    "        label = e.to_dict()[\"value\"]\n",
    "        confidence = round(float(e.to_dict()[\"confidence\"]), 2)\n",
    "        pred_dict[label] = confidence\n",
    "    return pred_dict\n",
    "\n",
    "\n",
    "predict_flair_tars(\"hello world\", tars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='/root/blog-multi-label/notebooks/model.joblib' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn\n",
    "from joblib import load\n",
    "\n",
    "wandb.restore(\n",
    "    \"model.joblib\",\n",
    "    \"/\".join(project_artifacts.query('type == \"sklearn_linear_svc\"').iloc[0].run.path),\n",
    ")\n",
    "sklearn_linear_svc = load(\"./model.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x10 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_linear_svc.predict(['hello world'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exchange': 0,\n",
       " 'inflation': 0,\n",
       " 'insurance': 0,\n",
       " 'property': 0,\n",
       " 'public_institution': 0,\n",
       " 'stocks': 1,\n",
       " 'super': 0,\n",
       " 'tax': 0,\n",
       " 'toxic': 0,\n",
       " 'workplace': 0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_sklearn_linear_svc(text, sklearn_linear_svc_model):\n",
    "    return dict(\n",
    "        zip(sklearn_linear_svc_model.multi_label_classes_,\n",
    "            sklearn_linear_svc_model.predict([text])[0].toarray()[0],\n",
    "        )\n",
    "    )\n",
    "\n",
    "predict_sklearn_linear_svc('The RBA has too much power and this frightens me', sklearn_linear_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary classifier\n",
    "wandb.restore(\n",
    "    \"label_dictionary.json\",\n",
    "    \"/\".join(\n",
    "        project_artifacts.query('type == \"dictionary_classifier\"').iloc[0].run.path\n",
    "    ),\n",
    ")\n",
    "\n",
    "import srsly\n",
    "from clear_bow.classifier import DictionaryClassifier\n",
    "\n",
    "dc = DictionaryClassifier(\n",
    "    classifier_type=\"multi_label\",\n",
    "    label_dictionary=srsly.read_json(\"./label_dictionary.json\"),\n",
    ")\n",
    "dc.predict_single(\"hello world\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('p38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0a3389de74b7ec3a6acaa3d6c3d81172f0da4390709f30c0434c73a0ff8c437"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
